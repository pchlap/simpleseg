{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interobserver Variability\n",
    "\n",
    "This Notebook demonstrates how to compute the interobserver variability of your Atlas data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import re\n",
    "import time\n",
    "\n",
    "sys.path.append('../../..')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "# Format the output a bit nicer for Jupyter\n",
    "logger.remove()\n",
    "logger.add(sys.stdout, format=\"{time:YYYY-MM-DD HH:mm:ss} {level} {message}\", level=\"DEBUG\")\n",
    "\n",
    "data_path = './data'\n",
    "working_path = \"./working\"\n",
    "if not os.path.exists(working_path):\n",
    "    os.makedirs(working_path)\n",
    "\n",
    "# Read the data into a dictionary\n",
    "\n",
    "data = {}\n",
    "\n",
    "for root, dirs, files in os.walk(data_path, topdown=False):\n",
    "    \n",
    "    if root == data_path:\n",
    "        continue\n",
    "        \n",
    "    case = root.split('/')[-1]\n",
    "    data[case] = {}\n",
    "    for f in files:\n",
    "        file_path = os.path.join(root, f)\n",
    "        \n",
    "        name = f.split('.')[0].upper()\n",
    "        \n",
    "        # Clean up names with double underscore:\n",
    "        name = name.replace('__','_')\n",
    "        \n",
    "        observer = None\n",
    "        \n",
    "        matches = re.findall(r\"(.*)_([0-9])\", f.split('.')[0])\n",
    "        \n",
    "        if len(matches) > 0:\n",
    "            name = matches[0][0].upper()\n",
    "            observer = matches[0][1]\n",
    "        \n",
    "        if observer: \n",
    "            if name in data[case]:\n",
    "                data[case][name][observer] = file_path\n",
    "            else:\n",
    "                data[case][name] = {observer: file_path}\n",
    "                \n",
    "        else:\n",
    "            data[case][name] = file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the interobserver variability for each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inter_ob_var_file = os.path.join(working_path, \"df_inter_ob_var.pkl\")\n",
    "\n",
    "# If already computed, read the data from a file\n",
    "if os.path.exists(df_inter_ob_var_file):\n",
    "    print(f'Reading from file: {df_inter_ob_var_file}')\n",
    "    df_inter_ob_var = pd.read_pickle(df_inter_ob_var_file)\n",
    "else:\n",
    "\n",
    "    inter_observe_var = []\n",
    "\n",
    "    for c in data:\n",
    "        for s in data[c]:\n",
    "            if not s.startswith('STRUCT_'):\n",
    "                continue\n",
    "\n",
    "            for o1 in data[c][s]:\n",
    "                for o2 in data[c][s]:\n",
    "\n",
    "                    if o1==o2:\n",
    "                        continue\n",
    "\n",
    "                    mask_1 = sitk.ReadImage(data[c][s][o1])\n",
    "                    mask_2 = sitk.ReadImage(data[c][s][o2])\n",
    "\n",
    "                    lomif = sitk.LabelOverlapMeasuresImageFilter()\n",
    "                    lomif.Execute(mask_1, mask_2)\n",
    "\n",
    "                    hdif = sitk.HausdorffDistanceImageFilter()\n",
    "                    hdif.Execute(mask_1, mask_2)\n",
    "\n",
    "                    dce = lomif.GetDiceCoefficient()\n",
    "                    hmax = hdif.GetHausdorffDistance()\n",
    "                    havg = hdif.GetAverageHausdorffDistance()\n",
    "\n",
    "                    row = {'o1': o1, \n",
    "                           'o2': o2, \n",
    "                           'case': c, \n",
    "                           'struct': s, \n",
    "                           'dce': dce, \n",
    "                           'hausdorff_max': hmax, \n",
    "                           'hausdorff_avg': havg }\n",
    "\n",
    "                    inter_observe_var.append(row)\n",
    "\n",
    "    df_inter_ob_var = pd.DataFrame(inter_observe_var)\n",
    "    print(f'Saving to file: {df_inter_ob_var_file}')\n",
    "    df_inter_ob_var.to_pickle(df_inter_ob_var_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inter = df_inter_ob_var.groupby(['struct']).aggregate(['mean', 'std', 'min', 'max'])\n",
    "df_inter = df_inter[['dce','hausdorff_max','hausdorff_avg']]\n",
    "df_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
